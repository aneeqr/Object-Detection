{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all libaraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets load our trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"save.model4\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/opencv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV (Open Source Computer Vision) is a library with functions that mainly aiming real-time computer vision. OpenCV supports Deep Learning frameworks **Caffe, Tensorflow, Torch/PyTorch.**\n",
    "\n",
    "With OpenCV you can perform face detection using pre-trained deep learning face detector model which is shipped with the library. OpenCV’s face detector is based on the **Single Shot Detector framework** with a **ResNet** base network.\n",
    "\n",
    "For more information on comparison accross various libaries please see:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Face Detection – OpenCV, Dlib and Deep Learning ( C++ / Python )**](https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Face Detector in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was included in OpenCV from version **3.3**. It is based on [Single-Shot-Multibox](https://arxiv.org/abs/1512.02325) detector and uses **ResNet-10** Architecture as backbone. The model was trained using images available from the web, but the source is not disclosed. OpenCV provides 2 models for this face detector under this category.\n",
    "\n",
    "   1. Floating point 16 version of the original **Caffe** implementation ( 5.4 MB )\n",
    "   2. 8 bit quantized version using **Tensorflow** ( 2.7 MB )\n",
    "   \n",
    "The method has the following merits :\n",
    "\n",
    "   1. Most accurate out of the four [**Methods**](https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/) in the libaries described above.\n",
    "   2. Runs at real-time on CPU.\n",
    "   3. Works for different face orientations – up, down, left, right, side-face etc.\n",
    "   4. Works even under substantial occlusion.\n",
    "   5. Detects faces across of various sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use floating point model of Caffe, we use the **caffemodel** and **prototxt** files. \n",
    "\n",
    "Otherwise, we use the **quantized tensorflow model**. \n",
    "\n",
    "Also note the difference in the way we read the networks for Caffe and Tensorflow and the computations.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load our detector files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detector(DNN):\n",
    "    if DNN == \"Caffe\":\n",
    "        modelFile =  \"detector/res10_300x300_ssd_iter_140000_fp16.caffemodel\" \n",
    "        configFile = \"detector/deploy.prototxt\" \n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = \"detector/opencv_face_detector_uint8.pb\"\n",
    "        configFile = \"detector/opencv_face_detector.pbtxt\"\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets read our set of images. When the image file is read with the OpenCV function imread(), the order of the colour is `(B, G, R)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.sep.join([r'testfiles/',\"example_01.png\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 600, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing blob from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to construct blobs for our test images. Similar to our training test, for our test test also we first need to pre-process our test images. This will help our deep neural networks perform better. **Pre-processing is handled by openCVs blobfromImage function.**\n",
    "\n",
    "A blob is just a (potentially collection) of image(s) with the same spatial dimensions (i.e., width and height), same depth (number of channels), that have all be preprocessed in the same manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert the image to a blob from the image using openCVs [blobfromImage](https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/) and pass it through the network using the forward() function.\n",
    "\n",
    "The **blobfromimage** function of openCV performs:\n",
    "   1. Mean subtraction\n",
    "   2. Image scaling\n",
    "   3. RGB Channel Swapping.\n",
    "\n",
    "\n",
    "### Mean subtraction\n",
    "\n",
    "In order to handle intensity variations and normalization, sometimes we calculate the average pixel value on the training dataset and subtract it from each image during training. If we are doing mean subtraction during training, then we must apply it during inference.\n",
    " \n",
    "Since our models have been trained with weights from **ImageNet** training, we use the the mean values for the ImageNet training set, which are are **R=103.93, G=116.77, and B=123.68**. We should also check if certain deep neural nets perform mean subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/meansub.png)\n",
    "Taken From:\n",
    "[Adrians blobfromImage explanation](https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This mean will be a tuple corresponding to R, G, B channels. Ensure your tuple is in the format `(R, G, B)` order with the default **swapRB = True** setting. \n",
    "**Mean subtraction** is used to help combat illumination changes in the input image.\n",
    "\n",
    "\n",
    "### Other parameters:\n",
    "\n",
    "**scalefactor:** how much we want to scale our images. If we want, we can scale our images by multiplying them by a constant number. A lot of times we divide all of our uint8 images by 255, this way all the pixels are between 0 and 1(0/255-255/255). The default value is 1.0 which means no scaling.\n",
    "\n",
    "**size:** The spatial size of the output image. It will be equal to the input size required for the follow-on neural networks as the output of blobFromImage.\n",
    "\n",
    "**mean:** This is the mean subtraction value from ImageNet.\n",
    "\n",
    "\n",
    "**swapRB:** Boolean to indicate if we want to swap the first and last channel in 3 channel image. OpenCV assumes images are in  `(B, G, R)` channel order; however, the **mean** value assumes we are using `(R, G, B)` order. To resolve this discrepancy we can swap the R and B channels in image  by setting this value to **True**. By default OpenCV performs this channel swapping for us.\n",
    "\n",
    "**crop:** Boolean flag to indicate if we want to center crop our images. If it’s set to True, the input image is cropped from the center in such a way that smaller dimension is equal to the corresponding dimension in size and other dimension is equal or larger. However, if we set it to False, it would preserve the aspect ratio and just resize to dimensions in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 300, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h, w) = image.shape[:2]\n",
    "print(h,w)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=[104, 117, 123])\n",
    "blob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first dimension is our total number of images.\n",
    "2. The second dimension is the total number of channels in our image.\n",
    "3. The thid dimension here is our image height.\n",
    "4. The fourth dimension is our image width. \n",
    "\n",
    "Having the second dimension contain the channels is “channels first” ordering. Having the channels as the last dimension is called “channels last” ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading our object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = load_detector(DNN='Caffe') \n",
    "net.setInput(blob) \n",
    "detections = net.forward()\n",
    "detections.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **net.forward()** function here is an object detection network and it return labels, probabilities, and bounding box coordinates.\n",
    "\n",
    "\n",
    "The **detections** variable is a 4-D matrix, where\n",
    "   1. The 3rd dimension iterates over the detected faces. \n",
    "   2. The fourth dimension contains information about the bounding box and score for each face. \n",
    "   **For example:** detections[0,0,0,2] gives the confidence score for the first face, and detections[0,0,0,3:7] give the bounding box.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.        , 0.99865437, 0.54847866, 0.12316754,\n",
       "       0.67100626, 0.35501212], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First face probability of detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99865437"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First face Bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54847866, 0.12316754, 0.67100626, 0.35501212], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,0,3:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output coordinates of the bounding box are normalized between [0,1]. Thus the coordinates should be multiplied by the height and width of the original image to get the correct bounding box on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify a threshold to filter out weak detections and multiply the box with the original images width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.08719778  61.58376858 402.60375738 177.50605941]\n",
      "[2496.37870789 2000.04816055 2903.20243835 2492.21229553]\n",
      "[524.63046312 193.2027936  537.14622259 210.96256375]\n",
      "[  96.52560353 1997.42662907  512.41099834 2489.26997185]\n",
      "[517.99521446 180.28657138 530.17830849 199.18651879]\n",
      "[505.34330606 170.52203417 517.48627424 187.78061867]\n",
      "[518.2597518  172.77945578 529.57760096 188.48751485]\n",
      "[504.58052158 187.5872612  518.67799759 208.47991109]\n",
      "[ 13.02573681  61.72707677 590.78292847 438.72758746]\n",
      "[2411.81688309   63.64038587 2985.8622551   438.62167001]\n",
      "[246.42219543 413.96456957 276.65587664 486.61243916]\n",
      "[504.37996387 157.14120865 518.36743355 175.35701394]\n",
      "[487.42647171 173.08168113 499.35772419 189.8663491 ]\n",
      "[396.21874094  97.25946933 423.03797007 143.57316494]\n",
      "[494.68964338 156.60759807 508.60630274 176.80442333]\n",
      "[511.13369465 158.34522247 525.45261383 181.66083097]\n",
      "[481.2608242  180.06406724 494.19021606 198.79747927]\n",
      "[501.14843845 148.53717387 516.36164188 166.83028638]\n",
      "[519.70460415 199.00381565 535.46304703 224.88021851]\n",
      "[523.12982082 174.80626702 536.34910583 191.74903631]\n",
      "[496.80397511 195.12008131 516.2828207  229.90955412]\n",
      "[506.80947304 204.3761611  526.8979311  230.58781028]\n",
      "[520.86625099 162.32463717 535.40575504 182.29827285]\n",
      "[ 697.08788395 2004.38046455 1098.32832813 2475.1431942 ]\n",
      "[479.47829962 137.98369467 498.82889986 164.66422379]\n",
      "[529.22501564 158.77252817 544.16620731 177.50811577]\n",
      "[469.07404661 176.13683641 482.35849142 193.62531602]\n",
      "[532.36377239 188.33974004 547.26827145 206.995368  ]\n",
      "[481.61841631 192.2301203  501.62812471 221.73787653]\n",
      "[484.51291323 151.57908201 501.2829423  177.87909508]\n",
      "[531.35086298 172.28218913 545.12046576 188.74964118]\n",
      "[469.28519011 113.01623285 503.06943655 156.4732641 ]\n",
      "[491.36223793 186.63971126 505.23269176 204.47711647]\n",
      "[248.79984856   2.20486149 314.60856199  91.89887345]\n",
      "[410.11612415 110.04051566 432.88779259 139.93960619]\n",
      "[ 100.75998902 1526.06344223  534.90149975 1948.33087921]\n",
      "[473.83464575 159.87059474 488.72412443 181.31807446]\n",
      "[465.96361399 184.78541076 481.60375357 204.32589948]\n",
      "[539.0093565  190.46039879 558.36510658 228.68035734]\n",
      "[483.20757151 106.25592619 520.132792   146.86043561]\n",
      "[ 102.19767094 1030.62772751  544.59614754 1470.04032135]\n",
      "[469.87792253 155.72156012 535.83687544 236.2716645 ]\n",
      "[539.85729218 179.57633734 556.99131489 205.87962866]\n",
      "[427.10773945 121.66768312 451.50547028 158.59752893]\n",
      "[509.67704058 149.21867847 524.00568724 165.55500031]\n",
      "[ 92.19996929 532.43237734 537.43958473 969.78384256]\n",
      "[456.65477514 172.97230661 474.17281866 197.04504311]\n",
      "[1267.38667488 2020.94817162 1717.80867577 2452.78429985]\n",
      "[425.79950094 101.67068243 447.11090326 131.88245893]\n",
      "[546.76058292 121.19249254 572.72815704 167.73509979]\n",
      "[1901.26991272 2007.78198242 2300.37975311 2479.67386246]\n",
      "[535.74736118 144.94913816 554.11334038 165.83862901]\n",
      "[312.30018139 203.23212445 336.03043556 249.55762923]\n",
      "[2489.85528946 1534.42120552 2910.18877029 1955.80339432]\n",
      "[523.34589958 149.48511124 539.9107933  172.17317224]\n",
      "[440.96041918 137.45631278 507.53628016 219.58087385]\n",
      "[2487.02688217  536.21530533 2912.80374527  954.01740074]\n",
      "[443.75406504 138.77047598 466.61478281 177.14764178]\n",
      "[107.95761645  31.36452287 153.63301635  90.8908397 ]\n",
      "[390.5985117   61.1647293  420.13170719  91.52562171]\n",
      "[543.79756451 156.48315847 563.67852688 184.53632295]\n",
      "[475.58830976 202.71244645 503.1716466  246.28266692]\n",
      "[526.89406872 205.26450872 545.03703117 229.05310988]\n",
      "[551.18969679 204.31382954 574.98954535 232.50852525]\n",
      "[489.64269161 218.29360723 515.10765553 250.26321411]\n",
      "[498.86988401 132.31615722 518.88774633 152.15270221]\n",
      "[456.41781092  94.35066581 525.45973063 186.0473156 ]\n",
      "[2487.17536926 1034.46769714 2908.6938858  1461.06648445]\n",
      "[ 33.68815184 221.55991197  52.22461224 250.99122524]\n",
      "[510.30600071 216.80486202 532.29911327 247.66018987]\n",
      "[458.67605209 140.83044231 478.4924984  165.53495824]\n",
      "[150.56775212  31.18782677 191.20396972  88.73338997]\n",
      "[132.91448951 253.17847729 160.93502641 285.06678343]\n",
      "[406.43749237 153.52784097 439.8015976  209.34657753]\n",
      "[307.27661848 221.93308175 327.25807428 246.30378187]\n",
      "[ 49.53779876 226.61976516  69.20979023 252.99936533]\n",
      "[406.75874949  93.0776     429.07150984 115.10773003]\n",
      "[440.46885967 111.52040213 465.66245556 145.5194056 ]\n",
      "[ 55.46772927 197.24658132  93.84380579 240.74524641]\n",
      "[435.9510541  326.14710927 513.0179286  412.92575002]\n",
      "[461.18330956 188.05669248 483.85033607 225.81420839]\n",
      "[330.76483011 203.910321   358.32649469 263.43384385]\n",
      "[  4.46647704 168.84595156 169.22800541 346.69399261]\n",
      "[364.03115988 311.85150146 444.73539591 389.85866308]\n",
      "[449.98755455 179.20652032 469.20518875 209.50138569]\n",
      "[461.44030094 156.25023842 479.2630434  178.67100239]\n",
      "[ 91.06829166 220.30588984 124.66002703 259.91585851]\n",
      "[519.64713335 179.36511338 584.99504328 265.23274183]\n",
      "[ 70.88490129 219.66433525 100.77098608 256.15879893]\n",
      "[523.78492355 210.9323293  550.60529709 249.40605462]\n",
      "[248.13378453 410.62924266 267.23672748 448.28912616]\n",
      "[374.62638617  98.53544831 432.48013258 177.43948102]\n",
      "[294.99390721 219.17499602 315.71102142 250.1527667 ]\n",
      "[305.04294634 233.75324905 324.92948771 286.25029325]\n",
      "[117.22868085 217.60138869 197.06938863 285.93596816]\n",
      "[ 31.97507411 239.18899894  51.66692287 269.36003566]\n",
      "[383.2621336  163.65543008 428.34062576 221.60837054]\n",
      "[ 40.78251421 198.89381528  71.96937203 243.61294508]\n",
      "[452.8411746  128.03700566 475.64030886 153.74621749]\n",
      "[185.4973197  141.28957689 216.0539031  198.89761508]\n",
      "[105.5734992  254.2385757  135.19163132 290.10477662]\n",
      "[ 685.16221046   47.55738378 1113.78679276  454.35151458]\n",
      "[412.41284609 130.10464609 441.93044901 173.21665585]\n",
      "[428.59371901  90.64404666 449.65492487 112.37183213]\n",
      "[537.60817051 211.90148592 570.38619518 255.79041243]\n",
      "[528.26786041 130.3576678  550.34816265 159.48008001]\n",
      "[ 12.50029206 232.44918883  35.62232852 270.28048038]\n",
      "[495.66149712 128.3596009  563.2324934  211.35242283]\n",
      "[1889.76516724   47.08296061 2320.03011703  452.8734982 ]\n",
      "[426.79957151 160.37473083 454.84060049 200.63400269]\n",
      "[413.42232227 327.77807117 468.02344322 381.1608851 ]\n",
      "[441.24991894 414.89580274 470.86687088 476.47842765]\n",
      "[278.89357209 374.94158745 311.39262915 438.45659494]\n",
      "[ 17.08288863 209.84083414  34.15206447 232.23310709]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "threshold=0.5\n",
    "for i in range(0, detections.shape[2]):\n",
    "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert to int and make sure that our bounding boxes falls in the dimensions of our frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 61, 402, 177)\n",
      "(329, 61, 402, 177)\n",
      "(2496, 2000, 2903, 2492)\n",
      "(2496, 2000, 599, 499)\n",
      "(524, 193, 537, 210)\n",
      "(524, 193, 537, 210)\n",
      "(96, 1997, 512, 2489)\n",
      "(96, 1997, 512, 499)\n",
      "(517, 180, 530, 199)\n",
      "(517, 180, 530, 199)\n",
      "(505, 170, 517, 187)\n",
      "(505, 170, 517, 187)\n",
      "(518, 172, 529, 188)\n",
      "(518, 172, 529, 188)\n",
      "(504, 187, 518, 208)\n",
      "(504, 187, 518, 208)\n",
      "(13, 61, 590, 438)\n",
      "(13, 61, 590, 438)\n",
      "(2411, 63, 2985, 438)\n",
      "(2411, 63, 599, 438)\n",
      "(246, 413, 276, 486)\n",
      "(246, 413, 276, 486)\n",
      "(504, 157, 518, 175)\n",
      "(504, 157, 518, 175)\n",
      "(487, 173, 499, 189)\n",
      "(487, 173, 499, 189)\n",
      "(396, 97, 423, 143)\n",
      "(396, 97, 423, 143)\n",
      "(494, 156, 508, 176)\n",
      "(494, 156, 508, 176)\n",
      "(511, 158, 525, 181)\n",
      "(511, 158, 525, 181)\n",
      "(481, 180, 494, 198)\n",
      "(481, 180, 494, 198)\n",
      "(501, 148, 516, 166)\n",
      "(501, 148, 516, 166)\n",
      "(519, 199, 535, 224)\n",
      "(519, 199, 535, 224)\n",
      "(523, 174, 536, 191)\n",
      "(523, 174, 536, 191)\n",
      "(496, 195, 516, 229)\n",
      "(496, 195, 516, 229)\n",
      "(506, 204, 526, 230)\n",
      "(506, 204, 526, 230)\n",
      "(520, 162, 535, 182)\n",
      "(520, 162, 535, 182)\n",
      "(697, 2004, 1098, 2475)\n",
      "(697, 2004, 599, 499)\n",
      "(479, 137, 498, 164)\n",
      "(479, 137, 498, 164)\n",
      "(529, 158, 544, 177)\n",
      "(529, 158, 544, 177)\n",
      "(469, 176, 482, 193)\n",
      "(469, 176, 482, 193)\n",
      "(532, 188, 547, 206)\n",
      "(532, 188, 547, 206)\n",
      "(481, 192, 501, 221)\n",
      "(481, 192, 501, 221)\n",
      "(484, 151, 501, 177)\n",
      "(484, 151, 501, 177)\n",
      "(531, 172, 545, 188)\n",
      "(531, 172, 545, 188)\n",
      "(469, 113, 503, 156)\n",
      "(469, 113, 503, 156)\n",
      "(491, 186, 505, 204)\n",
      "(491, 186, 505, 204)\n",
      "(248, 2, 314, 91)\n",
      "(248, 2, 314, 91)\n",
      "(410, 110, 432, 139)\n",
      "(410, 110, 432, 139)\n",
      "(100, 1526, 534, 1948)\n",
      "(100, 1526, 534, 499)\n",
      "(473, 159, 488, 181)\n",
      "(473, 159, 488, 181)\n",
      "(465, 184, 481, 204)\n",
      "(465, 184, 481, 204)\n",
      "(539, 190, 558, 228)\n",
      "(539, 190, 558, 228)\n",
      "(483, 106, 520, 146)\n",
      "(483, 106, 520, 146)\n",
      "(102, 1030, 544, 1470)\n",
      "(102, 1030, 544, 499)\n",
      "(469, 155, 535, 236)\n",
      "(469, 155, 535, 236)\n",
      "(539, 179, 556, 205)\n",
      "(539, 179, 556, 205)\n",
      "(427, 121, 451, 158)\n",
      "(427, 121, 451, 158)\n",
      "(509, 149, 524, 165)\n",
      "(509, 149, 524, 165)\n",
      "(92, 532, 537, 969)\n",
      "(92, 532, 537, 499)\n",
      "(456, 172, 474, 197)\n",
      "(456, 172, 474, 197)\n",
      "(1267, 2020, 1717, 2452)\n",
      "(1267, 2020, 599, 499)\n",
      "(425, 101, 447, 131)\n",
      "(425, 101, 447, 131)\n",
      "(546, 121, 572, 167)\n",
      "(546, 121, 572, 167)\n",
      "(1901, 2007, 2300, 2479)\n",
      "(1901, 2007, 599, 499)\n",
      "(535, 144, 554, 165)\n",
      "(535, 144, 554, 165)\n",
      "(312, 203, 336, 249)\n",
      "(312, 203, 336, 249)\n",
      "(2489, 1534, 2910, 1955)\n",
      "(2489, 1534, 599, 499)\n",
      "(523, 149, 539, 172)\n",
      "(523, 149, 539, 172)\n",
      "(440, 137, 507, 219)\n",
      "(440, 137, 507, 219)\n",
      "(2487, 536, 2912, 954)\n",
      "(2487, 536, 599, 499)\n",
      "(443, 138, 466, 177)\n",
      "(443, 138, 466, 177)\n",
      "(107, 31, 153, 90)\n",
      "(107, 31, 153, 90)\n",
      "(390, 61, 420, 91)\n",
      "(390, 61, 420, 91)\n",
      "(543, 156, 563, 184)\n",
      "(543, 156, 563, 184)\n",
      "(475, 202, 503, 246)\n",
      "(475, 202, 503, 246)\n",
      "(526, 205, 545, 229)\n",
      "(526, 205, 545, 229)\n",
      "(551, 204, 574, 232)\n",
      "(551, 204, 574, 232)\n",
      "(489, 218, 515, 250)\n",
      "(489, 218, 515, 250)\n",
      "(498, 132, 518, 152)\n",
      "(498, 132, 518, 152)\n",
      "(456, 94, 525, 186)\n",
      "(456, 94, 525, 186)\n",
      "(2487, 1034, 2908, 1461)\n",
      "(2487, 1034, 599, 499)\n",
      "(33, 221, 52, 250)\n",
      "(33, 221, 52, 250)\n",
      "(510, 216, 532, 247)\n",
      "(510, 216, 532, 247)\n",
      "(458, 140, 478, 165)\n",
      "(458, 140, 478, 165)\n",
      "(150, 31, 191, 88)\n",
      "(150, 31, 191, 88)\n",
      "(132, 253, 160, 285)\n",
      "(132, 253, 160, 285)\n",
      "(406, 153, 439, 209)\n",
      "(406, 153, 439, 209)\n",
      "(307, 221, 327, 246)\n",
      "(307, 221, 327, 246)\n",
      "(49, 226, 69, 252)\n",
      "(49, 226, 69, 252)\n",
      "(406, 93, 429, 115)\n",
      "(406, 93, 429, 115)\n",
      "(440, 111, 465, 145)\n",
      "(440, 111, 465, 145)\n",
      "(55, 197, 93, 240)\n",
      "(55, 197, 93, 240)\n",
      "(435, 326, 513, 412)\n",
      "(435, 326, 513, 412)\n",
      "(461, 188, 483, 225)\n",
      "(461, 188, 483, 225)\n",
      "(330, 203, 358, 263)\n",
      "(330, 203, 358, 263)\n",
      "(4, 168, 169, 346)\n",
      "(4, 168, 169, 346)\n",
      "(364, 311, 444, 389)\n",
      "(364, 311, 444, 389)\n",
      "(449, 179, 469, 209)\n",
      "(449, 179, 469, 209)\n",
      "(461, 156, 479, 178)\n",
      "(461, 156, 479, 178)\n",
      "(91, 220, 124, 259)\n",
      "(91, 220, 124, 259)\n",
      "(519, 179, 584, 265)\n",
      "(519, 179, 584, 265)\n",
      "(70, 219, 100, 256)\n",
      "(70, 219, 100, 256)\n",
      "(523, 210, 550, 249)\n",
      "(523, 210, 550, 249)\n",
      "(248, 410, 267, 448)\n",
      "(248, 410, 267, 448)\n",
      "(374, 98, 432, 177)\n",
      "(374, 98, 432, 177)\n",
      "(294, 219, 315, 250)\n",
      "(294, 219, 315, 250)\n",
      "(305, 233, 324, 286)\n",
      "(305, 233, 324, 286)\n",
      "(117, 217, 197, 285)\n",
      "(117, 217, 197, 285)\n",
      "(31, 239, 51, 269)\n",
      "(31, 239, 51, 269)\n",
      "(383, 163, 428, 221)\n",
      "(383, 163, 428, 221)\n",
      "(40, 198, 71, 243)\n",
      "(40, 198, 71, 243)\n",
      "(452, 128, 475, 153)\n",
      "(452, 128, 475, 153)\n",
      "(185, 141, 216, 198)\n",
      "(185, 141, 216, 198)\n",
      "(105, 254, 135, 290)\n",
      "(105, 254, 135, 290)\n",
      "(685, 47, 1113, 454)\n",
      "(685, 47, 599, 454)\n",
      "(412, 130, 441, 173)\n",
      "(412, 130, 441, 173)\n",
      "(428, 90, 449, 112)\n",
      "(428, 90, 449, 112)\n",
      "(537, 211, 570, 255)\n",
      "(537, 211, 570, 255)\n",
      "(528, 130, 550, 159)\n",
      "(528, 130, 550, 159)\n",
      "(12, 232, 35, 270)\n",
      "(12, 232, 35, 270)\n",
      "(495, 128, 563, 211)\n",
      "(495, 128, 563, 211)\n",
      "(1889, 47, 2320, 452)\n",
      "(1889, 47, 599, 452)\n",
      "(426, 160, 454, 200)\n",
      "(426, 160, 454, 200)\n",
      "(413, 327, 468, 381)\n",
      "(413, 327, 468, 381)\n",
      "(441, 414, 470, 476)\n",
      "(441, 414, 470, 476)\n",
      "(278, 374, 311, 438)\n",
      "(278, 374, 311, 438)\n",
      "(17, 209, 34, 232)\n",
      "(17, 209, 34, 232)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "threshold=0.5\n",
    "for i in range(0, detections.shape[2]):\n",
    "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "    print((startX, startY, endX, endY))\n",
    "    if (startX) < 0:\n",
    "        startX\n",
    "    if (endX) > w-1:\n",
    "        endX = w-1\n",
    "    if (startY) < 0:\n",
    "        startY = 0\n",
    "    if (endY) > h-1:\n",
    "        endY = h -1\n",
    "    print((startX, startY, endX, endY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be simplified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 61, 402, 177)\n",
      "(329, 61, 402, 177)\n",
      "(2496, 2000, 2903, 2492)\n",
      "(2496, 2000, 599, 499)\n",
      "(524, 193, 537, 210)\n",
      "(524, 193, 537, 210)\n",
      "(96, 1997, 512, 2489)\n",
      "(96, 1997, 512, 499)\n",
      "(517, 180, 530, 199)\n",
      "(517, 180, 530, 199)\n",
      "(505, 170, 517, 187)\n",
      "(505, 170, 517, 187)\n",
      "(518, 172, 529, 188)\n",
      "(518, 172, 529, 188)\n",
      "(504, 187, 518, 208)\n",
      "(504, 187, 518, 208)\n",
      "(13, 61, 590, 438)\n",
      "(13, 61, 590, 438)\n",
      "(2411, 63, 2985, 438)\n",
      "(2411, 63, 599, 438)\n",
      "(246, 413, 276, 486)\n",
      "(246, 413, 276, 486)\n",
      "(504, 157, 518, 175)\n",
      "(504, 157, 518, 175)\n",
      "(487, 173, 499, 189)\n",
      "(487, 173, 499, 189)\n",
      "(396, 97, 423, 143)\n",
      "(396, 97, 423, 143)\n",
      "(494, 156, 508, 176)\n",
      "(494, 156, 508, 176)\n",
      "(511, 158, 525, 181)\n",
      "(511, 158, 525, 181)\n",
      "(481, 180, 494, 198)\n",
      "(481, 180, 494, 198)\n",
      "(501, 148, 516, 166)\n",
      "(501, 148, 516, 166)\n",
      "(519, 199, 535, 224)\n",
      "(519, 199, 535, 224)\n",
      "(523, 174, 536, 191)\n",
      "(523, 174, 536, 191)\n",
      "(496, 195, 516, 229)\n",
      "(496, 195, 516, 229)\n",
      "(506, 204, 526, 230)\n",
      "(506, 204, 526, 230)\n",
      "(520, 162, 535, 182)\n",
      "(520, 162, 535, 182)\n",
      "(697, 2004, 1098, 2475)\n",
      "(697, 2004, 599, 499)\n",
      "(479, 137, 498, 164)\n",
      "(479, 137, 498, 164)\n",
      "(529, 158, 544, 177)\n",
      "(529, 158, 544, 177)\n",
      "(469, 176, 482, 193)\n",
      "(469, 176, 482, 193)\n",
      "(532, 188, 547, 206)\n",
      "(532, 188, 547, 206)\n",
      "(481, 192, 501, 221)\n",
      "(481, 192, 501, 221)\n",
      "(484, 151, 501, 177)\n",
      "(484, 151, 501, 177)\n",
      "(531, 172, 545, 188)\n",
      "(531, 172, 545, 188)\n",
      "(469, 113, 503, 156)\n",
      "(469, 113, 503, 156)\n",
      "(491, 186, 505, 204)\n",
      "(491, 186, 505, 204)\n",
      "(248, 2, 314, 91)\n",
      "(248, 2, 314, 91)\n",
      "(410, 110, 432, 139)\n",
      "(410, 110, 432, 139)\n",
      "(100, 1526, 534, 1948)\n",
      "(100, 1526, 534, 499)\n",
      "(473, 159, 488, 181)\n",
      "(473, 159, 488, 181)\n",
      "(465, 184, 481, 204)\n",
      "(465, 184, 481, 204)\n",
      "(539, 190, 558, 228)\n",
      "(539, 190, 558, 228)\n",
      "(483, 106, 520, 146)\n",
      "(483, 106, 520, 146)\n",
      "(102, 1030, 544, 1470)\n",
      "(102, 1030, 544, 499)\n",
      "(469, 155, 535, 236)\n",
      "(469, 155, 535, 236)\n",
      "(539, 179, 556, 205)\n",
      "(539, 179, 556, 205)\n",
      "(427, 121, 451, 158)\n",
      "(427, 121, 451, 158)\n",
      "(509, 149, 524, 165)\n",
      "(509, 149, 524, 165)\n",
      "(92, 532, 537, 969)\n",
      "(92, 532, 537, 499)\n",
      "(456, 172, 474, 197)\n",
      "(456, 172, 474, 197)\n",
      "(1267, 2020, 1717, 2452)\n",
      "(1267, 2020, 599, 499)\n",
      "(425, 101, 447, 131)\n",
      "(425, 101, 447, 131)\n",
      "(546, 121, 572, 167)\n",
      "(546, 121, 572, 167)\n",
      "(1901, 2007, 2300, 2479)\n",
      "(1901, 2007, 599, 499)\n",
      "(535, 144, 554, 165)\n",
      "(535, 144, 554, 165)\n",
      "(312, 203, 336, 249)\n",
      "(312, 203, 336, 249)\n",
      "(2489, 1534, 2910, 1955)\n",
      "(2489, 1534, 599, 499)\n",
      "(523, 149, 539, 172)\n",
      "(523, 149, 539, 172)\n",
      "(440, 137, 507, 219)\n",
      "(440, 137, 507, 219)\n",
      "(2487, 536, 2912, 954)\n",
      "(2487, 536, 599, 499)\n",
      "(443, 138, 466, 177)\n",
      "(443, 138, 466, 177)\n",
      "(107, 31, 153, 90)\n",
      "(107, 31, 153, 90)\n",
      "(390, 61, 420, 91)\n",
      "(390, 61, 420, 91)\n",
      "(543, 156, 563, 184)\n",
      "(543, 156, 563, 184)\n",
      "(475, 202, 503, 246)\n",
      "(475, 202, 503, 246)\n",
      "(526, 205, 545, 229)\n",
      "(526, 205, 545, 229)\n",
      "(551, 204, 574, 232)\n",
      "(551, 204, 574, 232)\n",
      "(489, 218, 515, 250)\n",
      "(489, 218, 515, 250)\n",
      "(498, 132, 518, 152)\n",
      "(498, 132, 518, 152)\n",
      "(456, 94, 525, 186)\n",
      "(456, 94, 525, 186)\n",
      "(2487, 1034, 2908, 1461)\n",
      "(2487, 1034, 599, 499)\n",
      "(33, 221, 52, 250)\n",
      "(33, 221, 52, 250)\n",
      "(510, 216, 532, 247)\n",
      "(510, 216, 532, 247)\n",
      "(458, 140, 478, 165)\n",
      "(458, 140, 478, 165)\n",
      "(150, 31, 191, 88)\n",
      "(150, 31, 191, 88)\n",
      "(132, 253, 160, 285)\n",
      "(132, 253, 160, 285)\n",
      "(406, 153, 439, 209)\n",
      "(406, 153, 439, 209)\n",
      "(307, 221, 327, 246)\n",
      "(307, 221, 327, 246)\n",
      "(49, 226, 69, 252)\n",
      "(49, 226, 69, 252)\n",
      "(406, 93, 429, 115)\n",
      "(406, 93, 429, 115)\n",
      "(440, 111, 465, 145)\n",
      "(440, 111, 465, 145)\n",
      "(55, 197, 93, 240)\n",
      "(55, 197, 93, 240)\n",
      "(435, 326, 513, 412)\n",
      "(435, 326, 513, 412)\n",
      "(461, 188, 483, 225)\n",
      "(461, 188, 483, 225)\n",
      "(330, 203, 358, 263)\n",
      "(330, 203, 358, 263)\n",
      "(4, 168, 169, 346)\n",
      "(4, 168, 169, 346)\n",
      "(364, 311, 444, 389)\n",
      "(364, 311, 444, 389)\n",
      "(449, 179, 469, 209)\n",
      "(449, 179, 469, 209)\n",
      "(461, 156, 479, 178)\n",
      "(461, 156, 479, 178)\n",
      "(91, 220, 124, 259)\n",
      "(91, 220, 124, 259)\n",
      "(519, 179, 584, 265)\n",
      "(519, 179, 584, 265)\n",
      "(70, 219, 100, 256)\n",
      "(70, 219, 100, 256)\n",
      "(523, 210, 550, 249)\n",
      "(523, 210, 550, 249)\n",
      "(248, 410, 267, 448)\n",
      "(248, 410, 267, 448)\n",
      "(374, 98, 432, 177)\n",
      "(374, 98, 432, 177)\n",
      "(294, 219, 315, 250)\n",
      "(294, 219, 315, 250)\n",
      "(305, 233, 324, 286)\n",
      "(305, 233, 324, 286)\n",
      "(117, 217, 197, 285)\n",
      "(117, 217, 197, 285)\n",
      "(31, 239, 51, 269)\n",
      "(31, 239, 51, 269)\n",
      "(383, 163, 428, 221)\n",
      "(383, 163, 428, 221)\n",
      "(40, 198, 71, 243)\n",
      "(40, 198, 71, 243)\n",
      "(452, 128, 475, 153)\n",
      "(452, 128, 475, 153)\n",
      "(185, 141, 216, 198)\n",
      "(185, 141, 216, 198)\n",
      "(105, 254, 135, 290)\n",
      "(105, 254, 135, 290)\n",
      "(685, 47, 1113, 454)\n",
      "(685, 47, 599, 454)\n",
      "(412, 130, 441, 173)\n",
      "(412, 130, 441, 173)\n",
      "(428, 90, 449, 112)\n",
      "(428, 90, 449, 112)\n",
      "(537, 211, 570, 255)\n",
      "(537, 211, 570, 255)\n",
      "(528, 130, 550, 159)\n",
      "(528, 130, 550, 159)\n",
      "(12, 232, 35, 270)\n",
      "(12, 232, 35, 270)\n",
      "(495, 128, 563, 211)\n",
      "(495, 128, 563, 211)\n",
      "(1889, 47, 2320, 452)\n",
      "(1889, 47, 599, 452)\n",
      "(426, 160, 454, 200)\n",
      "(426, 160, 454, 200)\n",
      "(413, 327, 468, 381)\n",
      "(413, 327, 468, 381)\n",
      "(441, 414, 470, 476)\n",
      "(441, 414, 470, 476)\n",
      "(278, 374, 311, 438)\n",
      "(278, 374, 311, 438)\n",
      "(17, 209, 34, 232)\n",
      "(17, 209, 34, 232)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n",
      "(0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "threshold=0.5\n",
    "for i in range(0, detections.shape[2]):\n",
    "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "    print((startX, startY, endX, endY))\n",
    "    \n",
    "    (startX, startY) = (max(0, startX), max(0, startY))\n",
    "    (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "    print((startX, startY, endX, endY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.sep.join([r'testfiles/',\"example_01.png\"]))\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=[104, 117, 123])\n",
    "net = load_detector(DNN='Caffe') \n",
    "net.setInput(blob) \n",
    "detections = net.forward()\n",
    "threshold=0.5\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2] # extract the confidence (i.e., probability) associated with  the detection\n",
    "    if confidence > threshold: #filter out weak detections.\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])#construct bounding box.\n",
    "            \n",
    "        (startX, startY, endX, endY) = box.astype(\"int\") #compute the x-y coordinates.\n",
    "        (startX, startY) = (max(0, startX), max(0, startY))#  ensure the bounding boxes fall within the dimensions of frame\n",
    "        (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "        face = image[startY:endY, startX:endX] # extract the face ROI\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB) #convert BGR to RGB\n",
    "        face = cv2.resize(face, (224, 224)) #resize to input of our cnn.\n",
    "        face = preprocess_input(img_to_array(face)) #pre-process \n",
    "        face = np.expand_dims(face, axis=0)    \n",
    "        (withoutMask, mask) = model.predict(face)[0]\n",
    "            \n",
    "        if mask > withoutMask:  #bgr  \n",
    "            label = \"Mask\"\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            label = \"No Mask\"\n",
    "            color = (0, 0, 255)\n",
    "            \n",
    "        # draw rectangles and text   \n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "        cv2.putText(image, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)    \n",
    "cv2.imshow(\"Output\", image) # Show image\n",
    "cv2.waitKey(0)    # Display the image infinitely until any keypress  waitKey(0) will display the window infinitely until any keypress (it is suitable for image display).0\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting this in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image_mask(threshold,image,net):\n",
    "    (h, w) = image.shape[:2] #get the height and width of image\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=[104, 117, 123]) #input blob\n",
    "    net.setInput(blob) #input blob to your net\n",
    "    detections = net.forward()\n",
    "\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] # extract the confidence (i.e., probability) associated with  the detection\n",
    "        if confidence > threshold: #filter out weak detections.\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])#construct bounding box.\n",
    "            \n",
    "            (startX, startY, endX, endY) = box.astype(\"int\") #compute the x-y coordinates.\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))#  ensure the bounding boxes fall within the dimensions of frame\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            face = image[startY:endY, startX:endX] # extract the face ROI\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB) #convert BGR to RGB\n",
    "            face = cv2.resize(face, (224, 224)) #resize to input of our cnn.\n",
    "            face = preprocess_input(img_to_array(face)) #pre-process \n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            \n",
    "            (withoutMask, mask) = model.predict(face)[0]\n",
    "            \n",
    "            if mask > withoutMask:  #bgr  \n",
    "                label = \"Mask\"\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                label = \"No Mask\"\n",
    "                color = (0, 0, 255)\n",
    "            \n",
    "            # draw rectangles and text   \n",
    "            label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "            cv2.putText(image, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "    \n",
    "    cv2.imshow(\"Output\", image) # Show image\n",
    "    cv2.waitKey(0)    # Display the image infinitely until any keypress  \n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.2\n",
    "for i in os.listdir('testfiles'):\n",
    "    net = load_detector(DNN='Caffe0')\n",
    "    image = cv2.imread(os.path.join('testfiles',i))\n",
    "    detect_image_mask(threshold,image, net)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform realtime face detection. Our code is exactly the same except for a few minor changes:\n",
    "    \n",
    "   1. We are detecting frames from video.\n",
    "   2. We stores all faces detected and their locations in these frames in lists.\n",
    "   3. If any faces are detected, we run our model trained earlier to give predictions.\n",
    "   4. We display these predictions and bounding boxes on these frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import time\n",
    "\n",
    "threshold=0.2\n",
    "net = load_detector(DNN='Caffe')\n",
    "\n",
    "#nitialize the video stream and allow the camera sensor to warm up\n",
    "vs = VideoStream(src=0).start() #// open the default camera\n",
    "time.sleep(2.0)\n",
    "while True:\n",
    "    videoframe = vs.read()\n",
    "    key=detect_video_mask(threshold,videoframe,net)\n",
    "    if key == ord(\"q\"): #ord function returns the ascii or decimal value of q. Bitwise and ensures this is equal when q is pressed.\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "vs.stream.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video_mask(threshold,videoframe,net):\n",
    "    (h, w) = videoframe.shape[:2] #get the height and width of videoframe\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(videoframe, scalefactor=1.0, size=(300, 300), mean=[104, 117, 123]) #input blob\n",
    "    net.setInput(blob) #input blob to your net\n",
    "    detections = net.forward()\n",
    "    \n",
    "    # initialize our list of faces, their corresponding locations.\n",
    "    faces = []\n",
    "    locs = []\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] # extract the confidence (i.e., probability) associated with  the detection\n",
    "        if confidence > threshold: #filter out weak detections.\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])#construct bounding box.\n",
    "            \n",
    "            (startX, startY, endX, endY) = box.astype(\"int\") #compute the x-y coordinates.\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))#  ensure the bounding boxes fall within the dimensions of frame\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            face = videoframe[startY:endY, startX:endX] # extract the face ROI\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB) #convert BGR to RGB\n",
    "            face = cv2.resize(face, (224, 224)) #resize to input of our cnn.\n",
    "            face = preprocess_input(img_to_array(face)) #pre-process \n",
    "            \n",
    "            faces.append(face) #store the face images and their locations.\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "            \n",
    "            \n",
    "            \n",
    "    predictions=[]  #intialize predictions.      \n",
    "    if len(faces) > 0: #if you detected at least one face.\n",
    "        faces = np.array(faces, dtype=\"float32\")\n",
    "        predictions =  model.predict(faces, batch_size=32) #predictions in batches to speed up flow.\n",
    "        for (bbox,pred) in zip(locs,predictions):\n",
    "            (startX, startY, endX, endY)=bbox\n",
    "            (withoutMask, mask)=pred\n",
    "            if mask > withoutMask:  #bgr  \n",
    "                label = \"Mask\"\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                label = \"No Mask\"\n",
    "                color = (0, 0, 255)\n",
    "           \n",
    "        # draw rectangles and text   \n",
    "            label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "            cv2.putText(videoframe, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(videoframe, (startX, startY), (endX, endY), color, 2)\n",
    "    cv2.imshow(\"Output\", videoframe) # Show image\n",
    "    key=cv2.waitKey(1) & 0xFF #  waitKey(1) will display a frame for 1 ms, after which display will be automatically closed\n",
    "    return key\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **cv2.waitKey()** will return the keyword that you press, in case if u just click on the close button when the window is opened then it will return -1.\n",
    "\n",
    "2. When you have pressed **'q'**, then cv2.waitkey() will return that **'q'** but the format it returns will be in string data type. In order to change it to binary, we are performing bitwise AND operation(&) with **0xFF** which is in **hexadecimal** format also know as hexadecimal constant, which is **255** in decimal or **11111111** in binary. \n",
    "\n",
    "**Note it is the same value in different formats**\n",
    "\n",
    "3. **'&'** in python is used to perform **bitwise AND operation.** \n",
    " \n",
    "### AND operation logic:\n",
    "1. 0&0=0\n",
    "2. 0&1=0\n",
    "3. 1&0=0\n",
    "4. 1&1=1\n",
    "\n",
    "\n",
    "\n",
    "| **Letter** | **ASCII Code** |  **Binary**  |\n",
    "|:------:|:----------:|:--------:|\n",
    "|    q   |     113    | 01110001 |\n",
    "\n",
    "4: since we have given the hexadecimal constant **0xFF** whose value in binary is 11111111, let's perform the bit AND OPERATION with the binary value of letter **'q'** which is  01110001.\n",
    "\n",
    "        q= 01110001\n",
    "      0xFF=11111111\n",
    "          ----------\n",
    "           01110001   ----->q so when do bitwise and operation we get the same value of q\n",
    "          ----------\n",
    "5. Pnce the bitwise operation is completed or performed, the result will change to the decimal format, so since we are using ord('q') function which will return the decimal value or ASCII value of 'q', so both will be equal the condition if condition becomes true and the loop will break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current method of detecting whether a person is wearing a mask or not is a two-step process:\n",
    "\n",
    "1. Perform face detection\n",
    "2. Apply our face mask detector to each face\n",
    "\n",
    "Face mask obscures part of the face. If enough of the face is obscured, the face cannot be detected, and therefore, the face mask detector will not be applied.\n",
    "\n",
    "We can also train a two class object detector with mask and no mask class. In this way the detector will be able to detect people with masks more effectively and our computational pipeline would be a single step avoiding the face detection stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_obj2",
   "language": "python",
   "name": "tf_obj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
